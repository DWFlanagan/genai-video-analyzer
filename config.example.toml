# GenAI Video Analyzer Configuration
# Copy this file to config.toml and customize as needed

[analyzer]
# Default LLM model for frame captioning
llm_model = "gemma2:2b"

# Default model for final summary generation
summary_model = "gpt-4"

# Scene detection threshold (higher = fewer scenes)
scene_threshold = 30.0

# Whether to transcribe audio by default
transcribe_audio = true

[models]
# Alternative models you can use
# Uncomment and modify as needed

# Vision models for frame captioning
# vision_models = [
#     "llava",
#     "gemma2:2b", 
#     "gpt-4-vision-preview"
# ]

# Text models for summaries
# text_models = [
#     "gpt-4",
#     "gpt-3.5-turbo",
#     "claude-3-sonnet"
# ]

[processing]
# Maximum number of frames to process (0 = no limit)
max_frames = 0

# Skip frames shorter than this duration (seconds)
min_scene_duration = 1.0

# Output format preferences
output_formats = ["txt", "md"]

[output]
# Default output directory (relative to video file if not absolute)
default_output_dir = "."

# Whether to create timestamped subdirectories
use_timestamp_dirs = false

# Filename templates
frame_captions_filename = "frame_captions.txt"
transcript_filename = "whisper_transcript.txt"
summary_filename = "video_summary.md"

[logging]
# Logging level (DEBUG, INFO, WARNING, ERROR)
level = "INFO"

# Log to file as well as console
log_to_file = false
log_filename = "video_analyzer.log"
